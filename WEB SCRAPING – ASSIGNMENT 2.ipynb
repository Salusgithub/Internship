{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e710f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (4.5.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\geopt\\appdata\\roaming\\python\\python39\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e19bc4",
   "metadata": {},
   "source": [
    "Python program to scrape data for “Data Analyst” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9394",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f536d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from selenium.common.exception import stateElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b215e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\geopt\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb79ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open naukri\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babafde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter designation\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52403b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0496dc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit search\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a777709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c30186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping location\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scrapping Company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping experience required\n",
    "exp_req=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_req[0:10]:\n",
    "    exp=i.text\n",
    "    exp_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75738d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73557ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compliance Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Xoom Inc</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>nurture.farm</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Truecaller</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Market Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ICF</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>Remote</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Compliance Data Analyst   \n",
       "1                                Senior Data Analyst   \n",
       "2                                       Data Analyst   \n",
       "3                                Market Data Analyst   \n",
       "4                        Data Analyst - CRM Platform   \n",
       "5                                       Data Analyst   \n",
       "6  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "7  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "8                          Python Data Analyst - WFH   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "7  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "8                                             Remote   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company Experience Required  \n",
       "0                                      Xoom Inc             0-3 Yrs  \n",
       "1                                  nurture.farm             3-8 Yrs  \n",
       "2                                    Truecaller             2-4 Yrs  \n",
       "3                                           ICF             1-4 Yrs  \n",
       "4                             Artech infosystem             1-6 Yrs  \n",
       "5                                           Jar             0-4 Yrs  \n",
       "6                                     Cognizant             3-8 Yrs  \n",
       "7                                     Cognizant             6-9 Yrs  \n",
       "8  hCapital Business Consulting Private Limited            5-10 Yrs  \n",
       "9                                     Accenture             6-8 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company':company_name, 'Experience Required':exp_required })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78da9f",
   "metadata": {},
   "source": [
    "# 2\n",
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbdf19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\geopt\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6574d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e265f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open naukri\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62308c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter designation\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e003474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3110e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit search\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44c4cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ae386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping location\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scrapping Company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping experience required\n",
    "exp_req=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_req[0:10]:\n",
    "    exp=i.text\n",
    "    exp_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41349511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e5a3f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity For Senior Data Scientist/ Busines...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                              Senior Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Opportunity For Senior Data Scientist/ Busines...   \n",
       "9                                  Lead ML Scientist   \n",
       "\n",
       "                                        Job Location                  Company  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis   \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech   \n",
       "4    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group   \n",
       "5  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates   \n",
       "6                 Bangalore/Bengaluru, Pune, Chennai                    Wipro   \n",
       "7  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra   \n",
       "8  Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...                     PayU   \n",
       "9                        Bangalore/Bengaluru, Mumbai        Fractal Analytics   \n",
       "\n",
       "  Experience Required  \n",
       "0             2-4 Yrs  \n",
       "1             4-7 Yrs  \n",
       "2            9-14 Yrs  \n",
       "3             5-9 Yrs  \n",
       "4            5-10 Yrs  \n",
       "5             5-8 Yrs  \n",
       "6            8-13 Yrs  \n",
       "7           10-14 Yrs  \n",
       "8             4-6 Yrs  \n",
       "9            6-10 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company':company_name, 'Experience Required':exp_required })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace30fc",
   "metadata": {},
   "source": [
    "# 3\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d31b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\geopt\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1533ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open naukri\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b79b3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter designation\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d9e6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit search\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c97ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location filter  \n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]/label/p/span[1]\")\n",
    "location.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0be4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary filter  \n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e311204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "exp_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b43679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping location\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scrapping Company name\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping experience required\n",
    "exp_req=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_req[0:10]:\n",
    "    exp=i.text\n",
    "    exp_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9ff4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(exp_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f96d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>RCPC</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>RCPC</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...</td>\n",
       "      <td>torcai digital media</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job Title  \\\n",
       "0                              Data Scientist   \n",
       "1             DigitalBCG GAMMA Data Scientist   \n",
       "2                              Data Scientist   \n",
       "3                         Lead Data Scientist   \n",
       "4                              Data Scientist   \n",
       "5           Data Scientist - Engine Algorithm   \n",
       "6   Data Activation Specialist - Adobe Target   \n",
       "7                             Data Specialist   \n",
       "8                              Data Scientist   \n",
       "9                              Data Scientist   \n",
       "10                             Data Scientist   \n",
       "11            DigitalBCG GAMMA Data Scientist   \n",
       "12                             Data Scientist   \n",
       "13                        Lead Data Scientist   \n",
       "14                             Data Scientist   \n",
       "15          Data Scientist - Engine Algorithm   \n",
       "16  Data Activation Specialist - Adobe Target   \n",
       "17                            Data Specialist   \n",
       "18                             Data Scientist   \n",
       "19                             Data Scientist   \n",
       "\n",
       "                                         Job Location  \\\n",
       "0                  Noida, Nagpur, Bangalore/Bengaluru   \n",
       "1                      New Delhi, Bangalore/Bengaluru   \n",
       "2                                    Gurgaon/Gurugram   \n",
       "3          Noida(Sector-59 Noida)\\n(WFH during Covid)   \n",
       "4                                    Gurgaon/Gurugram   \n",
       "5   Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "6   Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "7                                               Noida   \n",
       "8                                               Noida   \n",
       "9   Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "10                 Noida, Nagpur, Bangalore/Bengaluru   \n",
       "11                     New Delhi, Bangalore/Bengaluru   \n",
       "12                                   Gurgaon/Gurugram   \n",
       "13         Noida(Sector-59 Noida)\\n(WFH during Covid)   \n",
       "14                                   Gurgaon/Gurugram   \n",
       "15  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "16  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "17                                              Noida   \n",
       "18                                              Noida   \n",
       "19  Dehradun, Hyderabad/Secunderabad, Gurgaon/Guru...   \n",
       "\n",
       "                    Company Experience Required  \n",
       "0               GlobalLogic            8-10 Yrs  \n",
       "1   Boston Consulting Group             2-5 Yrs  \n",
       "2                IHS Markit             3-6 Yrs  \n",
       "3   R Systems International            7-10 Yrs  \n",
       "4                     Optum             2-7 Yrs  \n",
       "5              Primo Hiring             1-3 Yrs  \n",
       "6            Okda Solutions            7-10 Yrs  \n",
       "7                      RCPC             4-6 Yrs  \n",
       "8              NGI Ventures             0-5 Yrs  \n",
       "9      torcai digital media             2-7 Yrs  \n",
       "10              GlobalLogic            8-10 Yrs  \n",
       "11  Boston Consulting Group             2-5 Yrs  \n",
       "12               IHS Markit             3-6 Yrs  \n",
       "13  R Systems International            7-10 Yrs  \n",
       "14                    Optum             2-7 Yrs  \n",
       "15             Primo Hiring             1-3 Yrs  \n",
       "16           Okda Solutions            7-10 Yrs  \n",
       "17                     RCPC             4-6 Yrs  \n",
       "18             NGI Ventures             0-5 Yrs  \n",
       "19     torcai digital media             2-7 Yrs  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Job Title':job_title, 'Job Location':job_location, 'Company':company_name, 'Experience Required':exp_required })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778e07b",
   "metadata": {},
   "source": [
    "# 4\n",
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c24aa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open flipkart\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0af853dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cls.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68ddf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter item\n",
    "item = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "item.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53f22a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64a6f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "offer=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca0e05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "049a491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OAKLEY', 'VINCENT CHASE', 'LIZA ANGEL', 'Fastrack', 'VINCENT CHASE', 'PIRASO', 'john jacobs', 'OAKLEY', 'PIRASO', 'kingsunglasses', 'john jacobs', 'john jacobs', 'GANSTA', 'Fastrack', 'VINCENT CHASE', 'Fastrack', 'ROZZETTA CRAFT', 'OAKLEY', 'SHAAH COLLECTIONS', 'PHENOMENAL', 'john jacobs', 'OAKLEY', 'ROZZETTA CRAFT', 'ROYAL SON', 'Fastrack', 'Fastrack', 'OAKLEY', 'OAKLEY', 'PIRASO', 'ROYAL SON', 'john jacobs', 'OAKLEY', 'Fastrack', 'Fastrack', 'Fastrack', 'Fastrack', 'OAKLEY', 'VINCENT CHASE', 'ROYAL SON', 'Fastrack', 'john jacobs', 'OAKLEY', 'Fastrack', 'PIRASO', 'DEIXELS', 'SHAAH COLLECTIONS', 'SUNBEE', 'john jacobs', 'PIRASO', 'New Specs', 'john jacobs', 'ROZZETTA CRAFT', 'PIRASO', 'SHAAH COLLECTIONS', 'ROYAL SON', 'LIZA ANGEL', 'VINCENT CHASE', 'kingsunglasses', 'kingsunglasses', 'SHAAH COLLECTIONS', 'Silver Kartz', 'ROYAL SON', 'SHAAH COLLECTIONS', 'Sewell', 'Fastrack', 'ALIXERO', 'VINCENT CHASE', 'VINCENT CHASE', 'Fastrack', 'VINCENT CHASE', 'Singco India', 'ROYAL SON', 'SHAAH COLLECTIONS', 'SHAAH COLLECTIONS', 'New Specs', 'GANSTA', 'ROZZETTA CRAFT', 'ROYAL SON', 'Fastrack', 'NuVew', 'OAKLEY', 'VINCENT CHASE', 'LIZA ANGEL', 'Fastrack', 'VINCENT CHASE', 'PIRASO', 'john jacobs', 'OAKLEY', 'PIRASO', 'kingsunglasses', 'john jacobs', 'john jacobs', 'GANSTA', 'Fastrack', 'VINCENT CHASE', 'Fastrack', 'ROZZETTA CRAFT', 'OAKLEY', 'SHAAH COLLECTIONS', 'PHENOMENAL']\n",
      "['UV Protection Round Sunglasses (53)', 'Retro Square Sunglass', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (54)', 'Polarized, UV Protection, Riding Glasses Wayfarer Sungl...', 'UV Protection Round Sunglasses (54)', 'UV Protection, Polarized Wayfarer Sunglasses (Free Size...', 'Polarized, UV Protection Retro Square Sunglasses (54)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection Rectangular Sunglasses (Free Size)', 'Polarized, UV Protection Rectangular Sunglasses (60)', 'by Lenskart Polarized, UV Protection Retro Square Sungl...', 'UV Protection Rectangular Sunglasses (52)', 'UV Protection, Mirrored Wayfarer Sunglasses (54)', 'Polarized, UV Protection Aviator Sunglasses (58)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Wayfarer, Aviator Sunglasses (88)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (54)', 'by Lenskart Polarized, UV Protection Rectangular Sungla...', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', 'UV Protection, Mirrored Wayfarer Sunglasses (54)', 'Mirrored, Night Vision, UV Protection, Riding Glasses S...', 'UV Protection Shield Sunglasses (Free Size)', 'UV Protection, Riding Glasses Retro Square Sunglasses (...', 'Mirrored, UV Protection, Riding Glasses, Others Wrap-ar...', 'Polarized, UV Protection Round Sunglasses (52)', 'UV Protection Aviator Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', 'Polarized, UV Protection Retro Square Sunglasses (55)', 'UV Protection Aviator Sunglasses (62)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Round Sunglasses (52)', 'Mirrored, UV Protection, Riding Glasses, Others Round S...', 'UV Protection Retro Square Sunglasses (53)', 'Polarized, UV Protection Aviator Sunglasses (57)', 'Polarized, UV Protection Wayfarer, Retro Square Sunglas...', 'UV Protection Aviator Sunglasses (58)', 'UV Protection, Mirrored Aviator Sunglasses (57)', 'Rectangular Sunglass', 'Polarized, UV Protection Round Sunglasses (51)', 'Riding Glasses, Night Vision Spectacle Sunglasses (Fre...', 'UV Protection Wayfarer Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Cat-eye Sunglasses...', 'UV Protection Wayfarer Sunglasses (55)', 'UV Protection Aviator Sunglasses (59)', 'Rectangular Sunglass', 'UV Protection Aviator Sunglasses (54)', 'UV Protection Rectangular Sunglasses (55)', 'UV Protection Rectangular Sunglasses (53)', 'Polarized, UV Protection Retro Square Sunglasses (56)', 'Gradient, UV Protection Aviator Sunglasses (57)', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Wayfarer Sunglasse...', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection, Gradient Retro Square Sunglasses (62)', 'Rectangular Sunglass', 'UV Protection, Polarized, Mirrored Rectangular Sunglass...', 'UV Protection Retro Square Sunglasses (53)', 'UV Protection Clubmaster Sunglasses (47)', 'HOLBROOK Wayfarer Sunglass', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', 'Polarized, UV Protection Wayfarer Sunglasses (61)', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Wrap-around Sunglasses (Free Size)', 'Retro Square Sunglass', 'Pitchman R Round Sunglass', 'UV Protection Wayfarer Sunglasses (32)', 'Mirrored Aviator Sunglasses (55)', 'Polarized, UV Protection Aviator Sunglasses (53)', 'Retro Square Sunglass', 'Polarized Retro Square Sunglasses (Free Size)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (58)', 'Shield Sunglass', 'by Lenskart Polarized, UV Protection Cat-eye Sunglasses...', 'UV Protection, Gradient Butterfly Sunglasses (62)', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Round Sunglasses (53)', 'Retro Square Sunglass', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (54)', 'Polarized, UV Protection, Riding Glasses Wayfarer Sungl...', 'UV Protection Round Sunglasses (54)', 'UV Protection, Polarized Wayfarer Sunglasses (Free Size...', 'Polarized, UV Protection Retro Square Sunglasses (54)', 'UV Protection Aviator Sunglasses (58)', 'UV Protection Rectangular Sunglasses (Free Size)', 'by Lenskart Polarized, UV Protection Retro Square Sungl...', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Rectangular Sunglasses (52)', 'UV Protection, Mirrored Wayfarer Sunglasses (54)', 'Polarized, UV Protection Aviator Sunglasses (58)', 'UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Wayfarer, Aviator Sunglasses (88)', 'Polarized, UV Protection Retro Square Sunglasses (55)', 'UV Protection Rectangular Sunglasses (Free Size)', 'UV Protection Aviator Sunglasses (54)']\n",
      "['₹12,409', '₹999', '₹189', '₹869', '₹799', '₹237', '₹1,999', '₹10,159', '₹237', '₹269', '₹1,999', '₹1,999', '₹272', '₹679', '₹699', '₹719', '₹424', '₹8,629', '₹195', '₹186', '₹2,999', '₹7,369', '₹339', '₹559', '₹899', '₹719', '₹6,739', '₹8,989', '₹237', '₹339', '₹2,499', '₹584', '₹639', '₹759', '₹759', '₹1,039', '₹8,629', '₹7,909', '₹538', '₹759', '₹2,999', '₹6,739', '₹799', '₹237', '₹236', '₹179', '₹283', '₹2,499', '₹305', '₹265', '₹559', '₹999', '₹246', '₹179', '₹599', '₹150', '₹249', '₹272', '₹199', '₹179', '₹999', '₹799', '₹179', '₹251', '₹719', '₹275', '₹289', '₹639', '₹639', '₹699', '₹584', '₹639', '₹179', '₹179', '₹299', '₹202', '₹559', '₹559', '₹1,169', '₹168', '₹8,989', '₹12,409', '₹189', '₹869', '₹799', '₹237', '₹10,159', '₹999', '₹237', '₹269', '₹1,999', '₹1,999', '₹272', '₹679', '₹699', '₹719', '₹1,999', '₹424', '₹195', '₹186']\n",
      "['40% off', '44% off', '20% off', '85% off', '60% off', '86% off', '78% off', '50% off', '88% off', '86% off', '72% off', '72% off', '84% off', '86% off', '70% off', '62% off', '50% off', '75% off', '80% off', '82% off', '77% off', '50% off', '86% off', '83% off', '20% off', '87% off', '60% off', '85% off', '20% off', '65% off', '68% off', '68% off', '82% off', '87% off', '78% off', '88% off', '72% off', '72% off', '10% off', '77% off', '10% off', '50% off', '81% off', '13% off', '60% off', '85% off', '60% off', '10% off', '85% off', '82% off', '60% off', '50% off', '86% off', '15% off', '72% off', '20% off', '78% off', '10% off', '88% off', '81% off', '50% off', '10% off', '83% off', '72% off', '10% off', '20% off', '10% off', '10% off', '85% off', '77% off', '44% off', '77% off', '20% off', '15% off', '15% off', '20% off', '10% off', '10% off', '73% off', '15% off', '40% off', '10% off', '20% off', '85% off', '60% off', '86% off', '78% off', '44% off', '88% off', '86% off', '60% off', '72% off', '84% off', '86% off', '70% off', '62% off', '50% off', '75% off', '80% off', '82% off']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping brand\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            brand.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "        \n",
    "print(brand)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping desc\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in desc_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            desc.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(desc)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "\n",
    "#scrapping desc\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            price.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(price)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "\n",
    "#scrapping price\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    desc_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in desc_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            offer.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(offer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "045d4db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(desc),len(price),len(offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42b3465d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAKLEY</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>₹12,409</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Retro Square Sunglass</td>\n",
       "      <td>₹999</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹869</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹799</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Wayfarer, Aviator Sunglasses (88)</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>OAKLEY</td>\n",
       "      <td>Polarized, UV Protection Retro Square Sunglass...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹195</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹186</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                        Description  \\\n",
       "0              OAKLEY                UV Protection Round Sunglasses (53)   \n",
       "1       VINCENT CHASE                              Retro Square Sunglass   \n",
       "2          LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3            Fastrack              UV Protection Aviator Sunglasses (54)   \n",
       "4       VINCENT CHASE  Polarized, UV Protection, Riding Glasses Wayfa...   \n",
       "..                ...                                                ...   \n",
       "95           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "96     ROZZETTA CRAFT    UV Protection Wayfarer, Aviator Sunglasses (88)   \n",
       "97             OAKLEY  Polarized, UV Protection Retro Square Sunglass...   \n",
       "98  SHAAH COLLECTIONS   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "99         PHENOMENAL              UV Protection Aviator Sunglasses (54)   \n",
       "\n",
       "      Price    Offer  \n",
       "0   ₹12,409  40% off  \n",
       "1      ₹999  44% off  \n",
       "2      ₹189  20% off  \n",
       "3      ₹869  85% off  \n",
       "4      ₹799  60% off  \n",
       "..      ...      ...  \n",
       "95     ₹719  62% off  \n",
       "96   ₹1,999  50% off  \n",
       "97     ₹424  75% off  \n",
       "98     ₹195  80% off  \n",
       "99     ₹186  82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Brand':brand, 'Description':desc, 'Price':price, 'Offer':offer })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c321f",
   "metadata": {},
   "source": [
    "# 5\n",
    "\n",
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "\n",
    "You will reach to the below shown webpage .\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83f3443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\geopt\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3de28ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open flipkart\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cba76089",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cls.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f1bf25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter item\n",
    "item = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "item.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3349b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "baa82dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[4]/div/div/div/a\").click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbeb216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = driver.current_window_handle\n",
    "#get first child window\n",
    "chwnd = driver.window_handles\n",
    "for w in chwnd:\n",
    "   #switch focus to child window\n",
    "   if(w!=p):\n",
    "       driver.switch_to.window(w)\n",
    "       break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "22e30bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[10]/div[7]/div/a\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "862d0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "rating=[]\n",
    "summary=[]\n",
    "review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65f39c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping rating\n",
    "start=0\n",
    "end=10\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    all_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in all_tags:\n",
    "        if inc <= 100:\n",
    "            data=i.text\n",
    "            rating.append(data)\n",
    "    all_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in all_tags:\n",
    "        if inc <= 100:\n",
    "            data=i.text\n",
    "            summary.append(data)\n",
    "    all_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in all_tags:\n",
    "        if inc <= 100:\n",
    "            data=i.text\n",
    "            review.append(data)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "        \n",
    "        \n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d99c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(summary),len(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ccbd06c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       4      Value-for-money   \n",
       "2       5     Perfect product!   \n",
       "3       5  Best in the market!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5   Highly recommended   \n",
       "96      5     Perfect product!   \n",
       "97      5        Great product   \n",
       "98      5            Fabulous!   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                               Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   I'm Really happy with the product\\nDelivery wa...  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Great iPhone very snappy experience as apple k...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  What a camera .....just awesome ..you can feel...  \n",
       "96  Value for money\\n5 star rating\\nExcellent came...  \n",
       "97  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "98  This is my first iOS phone. I am very happy wi...  \n",
       "99  i11 is worthy to buy, too much happy with the ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Rating':rating, 'Summary':summary, 'Review':review })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3766aac9",
   "metadata": {},
   "source": [
    "# 6\n",
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "97acbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\geopt\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95b3067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open flipkart\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6dbe35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cls.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c1e4fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter item\n",
    "item = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "item.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a895486",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2697494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]\n",
    "offer=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1e2ca59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NIKE', 'RapidBox', 'RINDAS', 'K- FOOTLANCE', 'BRUTON', 'World Wear Footwear', 'RapidBox', 'K- FOOTLANCE', 'Fox Heaven', 'World Wear Footwear', 'Roadster', 'Furo', 'BRUTON', 'Kzaara', 'AMICO', 'Airland', 'RapidBox', 'BRUTON', 'RapidBox', 'Elevarse', 'EZDEZARIO', 'Layasa', 'WHITE WALKERS', 'Deals4you', 'aadi', 'Bond Street By Red Tape', 'NIKE', 'SUSON', 'Bond Street By Red Tape', 'Magnolia', 'BRUTON', 'NIKE', \"Neeman's\", 'HRX by Hrithik Roshan', 'asian', 'BRUTON', 'Mast & Harbour', 'CALCADOS', 'K- FOOTLANCE', 'HOTSTYLE', 'K- FOOTLANCE', 'NIKE', 'Labbin', 'RED TAPE', 'aadi', 'asian', 'Rzisbo', 'kartic', 'BRUTON', 'BRUTON', 'BB LAA', 'PUMA', 'RED TAPE', 'Kraasa', 'URBANBOX', 'ASTEROID', 'JYOTIFED FOOTWEARS', 'Kraasa', 'BRUTON', 'Deals4you', 'Kraasa', 'ONECENTRE', 'BRUTON', 'Shozie', 'World Wear Footwear', 'SCATCHITE', 'PUMA', 'WOODLAND', 'Robbie jones', 'PUMA', 'PUMA', 'PUMA', \"'Trends'\", \"K' Footlance\", 'WHITE WALKERS', 'Magnolia', 'LIBERTY', 'PUMA', 'BRUTON', 'tigonis', 'DUNKASTON', 'NIKE', 'RINDAS', 'K- FOOTLANCE', 'BRUTON', 'World Wear Footwear', 'RapidBox', 'RapidBox', 'Fox Heaven', 'World Wear Footwear', 'K- FOOTLANCE', 'Roadster', 'BRUTON', 'Kzaara', 'AMICO', 'Airland', 'Furo', 'RapidBox', 'RapidBox', 'Elevarse']\n",
      "['Sneakers For Men', 'SB CHECK Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Skypy-31 Walking Shoes,Training Shoes,Sneakers,Loafers,...', 'Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Lightweight Pack Of 1 Trendy Sneakers Sneakers For Men', 'Kenton Sneakers For Men', 'Sneakers For Men', 'Casuals, Canvas, Partywear Sneakers For Men', \"Original Luxury Branded Fashionable Men's Casual Walkin...\", 'SS1100 Sneakers For Men', 'Sneakers For Men', 'Lattest Sneakers Shoe Sneakers For Men', 'Sneakers For Women', 'Outdoors Casual Canvas Sneakers Gyming Walking Training...', 'Sneakers For Women', '2 Combo Sneaker Shoes Sneakers For Men', 'Sneakers For Men', 'Latest Collection-1215 Stylish Casual Sports Sneakers F...', 'Sneakers Sneakers For Men', 'Sneakers For Women', 'STR2 Sneakers For Men', 'Casual Sneakers Canvas Shoes For Men Sneakers For Men', 'Ralph Sampson Lo Sneakers For Men', \"Fiona Wn's Slipon Sneakers For Women\", 'Sneakers For Men', 'Fashion and Stylish Soft Ultralight Lace Up Sneakers Ca...', 'Stylish & Trending Outdoor Walking Comfortable Sneakers...', 'Sneakers For Men', 'Harrow Wns Sneakers For Women', 'Skye Clean Sneakers For Women', 'Exclusive Sneaker Shoes Sneakers For Men', 'Tigonis Casuals For Men Sneakers For Men (White) Sneake...', 'SB Alleyoop Skate Sneakers For Men', 'Stylish & Trendy Sneakers For Men', \"Perfect Stylish Casual Shoes For Girls & Women's Casual...\", 'Sneakers For Men', 'Sneaker Sneakers For Men', 'Latest Collection-1216 Stylish Casual Sports Sneakers F...', 'Sneakers For Men', 'Men Blue Solid Sneakers Sneakers For Men', \"Men's Fashion Trend Sneakers Sneakers For Men\", 'Latest Collection Black-349 Trendy & Stylish Casual Sne...', 'Casual shoes sports shoes womens shoes sneakers Sneaker...', 'Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', '350 smart grey lace-ups casual for men Sneakers For Men', 'Sneakers For Men', '2 Combo Sneaker Shoes Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Venture Runner Sneakers For Men', 'Stylish & Trending Outdoor Walking Comfortable Sneakers...', 'Sneakers For Women', 'Mesh | Ultralightweight | Comfortable | Breathable Walk...', 'Sneakers For Men', 'Sneakers For Men', 'Black Gym/Walking/Running Sports Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', '2 Combo Sneaker Shoes Sneakers For Men', 'Court Vintage Sneakers For Men', 'Sneakers For Men', 'HRX by Hrithik Roshan Men White Solid Sneakers with Per...', 'Skypy-31 Walking Shoes,Training Shoes,Sneakers,Loafers,...', 'Unique & Perfect Collection Combo Pack of 02 Shoes for ...', 'Sneakers For Men', 'ultra light Comfertable Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'SB CHECK Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Skypy-31 Walking Shoes,Training Shoes,Sneakers,Loafers,...', 'Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Lightweight Pack Of 1 Trendy Sneakers Sneakers For Men', 'Kenton Sneakers For Men', 'Sneakers For Men', 'Casuals, Canvas, Partywear Sneakers For Men', \"Original Luxury Branded Fashionable Men's Casual Walkin...\", 'Outdoors Casual Canvas Sneakers Gyming Walking Training...', 'Sneakers For Women', 'Lattest Sneakers Shoe Sneakers For Men', 'Sneakers For Women', 'Sneakers For Women', 'STR2 Sneakers For Men', '2 Combo Sneaker Shoes Sneakers For Men', 'Sneakers For Men', 'Latest Collection-1215 Stylish Casual Sports Sneakers F...', 'Sneakers Sneakers For Men', \"Fiona Wn's Slipon Sneakers For Women\"]\n",
      "['₹5,528', '₹499', '₹298', '₹389', '₹299', '₹298', '₹549', '₹1,639', '₹499', '₹289', '₹497', '₹999', '₹519', '₹199', '₹409', '₹171', '₹549', '₹499', '₹549', '₹292', '₹449', '₹4,671', '₹599', '₹455', '₹299', '₹1,529', '₹449', '₹399', '₹1,529', '₹396', '₹499', '₹3,826', '₹1,499', '₹1,629', '₹520', '₹332', '₹1,352', '₹284', '₹299', '₹293', '₹389', '₹289', '₹399', '₹1,499', '₹339', '₹420', '₹387', '₹6,684', '₹299', '₹199', '₹2,239', '₹599', '₹1,499', '₹449', '₹198', '₹499', '₹4,499', '₹439', '₹299', '₹363', '₹1,099', '₹239', '₹499', '₹478', '₹298', '₹360', '₹399', '₹499', '₹6,999', '₹399', '₹1,369', '₹2,796', '₹489', '₹369', '₹599', '₹399', '₹1,679', '₹2,450', '₹439', '₹298', '₹5,528', '₹6,684', '₹298', '₹389', '₹319', '₹199', '₹499', '₹549', '₹499', '₹299', '₹497', '₹1,639', '₹499', '₹289', '₹519', '₹409', '₹999', '₹549', '₹171', '₹292']\n",
      "['61% off', '55% off', '60% off', '70% off', '66% off', '47% off', '61% off', '68% off', '76% off', '66% off', '66% off', '70% off', '55% off', '80% off', '75% off', '56% off', '21% off', '76% off', '63% off', '52% off', '60% off', '80% off', '52% off', '40% off', '63% off', '75% off', '63% off', '6% off', '60% off', '20% off', '58% off', '62% off', '63% off', '50% off', '60% off', '50% off', '35% off', '78% off', '40% off', '14% off', '16% off', '70% off', '61% off', '75% off', '80% off', '50% off', '45% off', '66% off', '76% off', '50% off', '50% off', '50% off', '42% off', '60% off', '59% off', '62% off', '45% off', '65% off', '63% off', '80% off', '55% off', '45% off', '69% off', '50% off', '85% off', '55% off', '14% off', '70% off', '60% off', '60% off', '80% off', '50% off', '62% off', '86% off', '34% off', '14% off', '35% off', '70% off', '70% off', '61% off', '55% off', '60% off', '70% off', '66% off', '47% off', '61% off', '68% off', '76% off', '66% off', '40% off', '70% off', '55% off', '80% off', '75% off', '56% off', '21% off', '76% off', '63% off', '52% off', '60% off']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping brand\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            brand.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "        \n",
    "print(brand)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping desc\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    desc_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in desc_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            desc.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(desc)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "\n",
    "#scrapping desc\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            price.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(price)\n",
    "first_btn=driver.find_element(By.XPATH,'//a[@class=\"ge-49M _2Kfbh8\"]')\n",
    "first_btn.click()\n",
    "\n",
    "\n",
    "#scrapping price\n",
    "start=0\n",
    "end=3\n",
    "inc=1\n",
    "for page in range(start,end):\n",
    "    desc_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in desc_tags:\n",
    "        if inc <= 100:\n",
    "            br=i.text\n",
    "            offer.append(br)\n",
    "            inc=inc+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "print(offer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c4f5483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(desc),len(price),len(offer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fcd818bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIKE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹5,528</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>SB CHECK Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RINDAS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹298</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K- FOOTLANCE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Airland</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹409</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Furo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹999</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Latest Collection-1215 Stylish Casual Sports S...</td>\n",
       "      <td>₹549</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹171</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elevarse</td>\n",
       "      <td>Fiona Wn's Slipon Sneakers For Women</td>\n",
       "      <td>₹292</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                                        Description   Price  \\\n",
       "0           NIKE                                   Sneakers For Men  ₹5,528   \n",
       "1       RapidBox                          SB CHECK Sneakers For Men    ₹499   \n",
       "2         RINDAS                                   Sneakers For Men    ₹298   \n",
       "3   K- FOOTLANCE                                   Sneakers For Men    ₹389   \n",
       "4         BRUTON                                   Sneakers For Men    ₹299   \n",
       "..           ...                                                ...     ...   \n",
       "95       Airland             2 Combo Sneaker Shoes Sneakers For Men    ₹409   \n",
       "96          Furo                                   Sneakers For Men    ₹999   \n",
       "97      RapidBox  Latest Collection-1215 Stylish Casual Sports S...    ₹549   \n",
       "98      RapidBox                          Sneakers Sneakers For Men    ₹171   \n",
       "99      Elevarse               Fiona Wn's Slipon Sneakers For Women    ₹292   \n",
       "\n",
       "      Offer  \n",
       "0   61% off  \n",
       "1   55% off  \n",
       "2   60% off  \n",
       "3   70% off  \n",
       "4   66% off  \n",
       "..      ...  \n",
       "95  21% off  \n",
       "96  76% off  \n",
       "97  63% off  \n",
       "98  52% off  \n",
       "99  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Brand':brand, 'Description':desc, 'Price':price, 'Offer':offer })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2575995",
   "metadata": {},
   "source": [
    "# 7\n",
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "40edfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open myntra\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2beec4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location filter  \n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "location.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "10eb766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location filter  \n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "location.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9ba84c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "brand=[]\n",
    "desc=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "05d7c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[3]/a')\n",
    "first_btn.click()\n",
    "\n",
    "#scrapping brand\n",
    "start=0\n",
    "end=2\n",
    "inc1=1\n",
    "inc2=1\n",
    "inc3=1\n",
    "for page in range(start,end):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand_tags:\n",
    "        if inc1 <= 100:\n",
    "            br=i.text\n",
    "            brand.append(br)\n",
    "            inc1=inc1+1\n",
    "    desc_tags=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in desc_tags:\n",
    "        if inc2 <= 100:\n",
    "            br=i.text\n",
    "            desc.append(br)\n",
    "            inc2=inc2+1\n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in price_tags:\n",
    "        if inc3 <= 100:\n",
    "            br=i.text\n",
    "            price.append(br)\n",
    "            inc3=inc3+1\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@rel=\"next\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4bc8f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(desc),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4f7a3d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN LOW Basketball Shoe</td>\n",
       "      <td>Rs. 12795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men ZX 22 BOOST Sneakers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Eternity Nitro Running Shoes</td>\n",
       "      <td>Rs. 11049Rs. 12999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR SonicSE Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men ChargedEscape 3 BL Running</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TOMS</td>\n",
       "      <td>Men Slip-On Sneakers</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Velocity Nitro 2 Running</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Women Solid Leather Zip Up Boots</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Textured Block Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>Embellished PU Comfort Pumps</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                       Description  \\\n",
       "0               Nike    Men JORDAN LOW Basketball Shoe   \n",
       "1   ADIDAS Originals          Men ZX 22 BOOST Sneakers   \n",
       "2               Puma      Eternity Nitro Running Shoes   \n",
       "3       UNDER ARMOUR    Men HOVR SonicSE Running Shoes   \n",
       "4       UNDER ARMOUR    Men ChargedEscape 3 BL Running   \n",
       "..               ...                               ...   \n",
       "95              TOMS              Men Slip-On Sneakers   \n",
       "96              Puma    Women Velocity Nitro 2 Running   \n",
       "97              ALDO  Women Solid Leather Zip Up Boots   \n",
       "98              ALDO            Textured Block Sandals   \n",
       "99           fitflop      Embellished PU Comfort Pumps   \n",
       "\n",
       "                          Price  \n",
       "0                     Rs. 12795  \n",
       "1                     Rs. 11999  \n",
       "2   Rs. 11049Rs. 12999(15% OFF)  \n",
       "3                      Rs. 9999  \n",
       "4                      Rs. 8999  \n",
       "..                          ...  \n",
       "95                     Rs. 7499  \n",
       "96   Rs. 7699Rs. 10999(30% OFF)  \n",
       "97                    Rs. 12999  \n",
       "98                     Rs. 7999  \n",
       "99                     Rs. 7499  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Brand':brand, 'Description':desc, 'Price':price })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747f8d3",
   "metadata": {},
   "source": [
    "# 8\n",
    "Q8: Go to webpage https://www.amazon.in/\n",
    "\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f8633315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open amazon\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "74bd11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter item\n",
    "item = driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "item.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "88a2d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit\n",
    "btn=driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8736a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location cpu  \n",
    "cpu=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[5]/li[13]/span\")\n",
    "cpu.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3a1d7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "911861cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    br=i.text\n",
    "    title.append(br)\n",
    "    \n",
    "#scrapping rating\n",
    "rating_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-icon-alt\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    br=i.text\n",
    "    rating.append(br)\n",
    "\n",
    "#scrapping price\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    br=i.text\n",
    "    price.append(br)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "48bce64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(rating),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c1db7838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td></td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td></td>\n",
       "      <td>24,964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Lenovo Intel 6th Gen Core i7 12.5 In...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td></td>\n",
       "      <td>82,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td></td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...         1,00,000\n",
       "1  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...           82,490\n",
       "2  ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...           93,290\n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...           77,990\n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....           86,990\n",
       "5  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...           80,990\n",
       "6  HP Pavilion x360 11th Gen Intel Core i7 14 inc...           24,964\n",
       "7  (Renewed) Lenovo Intel 6th Gen Core i7 12.5 In...           59,990\n",
       "8  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...           82,490\n",
       "9  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...           99,990"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'Title':title, 'Rating':rating, 'Price':price })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c11fbe",
   "metadata": {},
   "source": [
    "# 9\n",
    "\n",
    "SKIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64727a5",
   "metadata": {},
   "source": [
    "# 10\n",
    "\n",
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "\n",
    "You have to scrape the data ticked in the above image.\n",
    "\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5d9b80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open ambitionbox\n",
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4aab6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salaries\n",
    "salaries=driver.find_element(By.XPATH,\"/html/body/div/div/div/footer/div[1]/div[3]/div/div[1]/ul/li[3]/a\")\n",
    "salaries.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0709061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter item\n",
    "item = driver.find_element(By.ID,\"jobProfileSearchbox\")\n",
    "item.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "67ac11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click\n",
    "click=driver.find_element(By.XPATH,\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div\")\n",
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5b8a7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "company=[]\n",
    "total_salary=[]\n",
    "average_salary=[]\n",
    "minimum_salary=[]\n",
    "maximum_salary=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2a59aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping company\n",
    "companys=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in companys[0:10]:\n",
    "    br=i.text\n",
    "    br1=br.split(\"\\n\")\n",
    "    cmp=br1[0]\n",
    "    company.append(cmp)\n",
    "    total_salary_split=br1[2].split('(')\n",
    "    total_salary.append(total_salary_split[1][:-1])\n",
    "    experience.append(total_salary_split[0])\n",
    "# print(experience)\n",
    "\n",
    "\n",
    "#scrapping average_salary\n",
    "datas=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in datas[0:10]:\n",
    "    br=i.text\n",
    "    average_salary.append(br)\n",
    "\n",
    "# print(average_salary)\n",
    "\n",
    "#scrapping minimum_salary\n",
    "datas=driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]')\n",
    "for i in datas[0:10]:\n",
    "    br=i.text\n",
    "    br1=br.split(\"\\n\")\n",
    "    minimum_salary.append(br1[0])\n",
    "    maximum_salary.append(br1[1])\n",
    "\n",
    "# print(maximum_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b7ade21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company), len(total_salary), len(average_salary), len(minimum_salary), len(maximum_salary), len(experience))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "aada9886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>minimum_salary</th>\n",
       "      <th>maximum_salary</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 24 salaries</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 59 salaries</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 35 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 118 salaries</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 70 salaries</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company           total_salary average_salary  \\\n",
       "0                     Walmart   based on 24 salaries        ₹ 32.2L   \n",
       "1                    Ab Inbev   based on 59 salaries        ₹ 19.8L   \n",
       "2                       Optum   based on 49 salaries        ₹ 16.4L   \n",
       "3                          ZS   based on 35 salaries        ₹ 15.9L   \n",
       "4           Fractal Analytics  based on 118 salaries        ₹ 15.5L   \n",
       "5           Sigmoid Analytics   based on 10 salaries        ₹ 14.7L   \n",
       "6             Tiger Analytics   based on 70 salaries        ₹ 14.6L   \n",
       "7  Legato Health Technologies   based on 11 salaries        ₹ 14.5L   \n",
       "8                        HSBC   based on 10 salaries        ₹ 14.0L   \n",
       "9                    Tredence   based on 14 salaries        ₹ 13.9L   \n",
       "\n",
       "  minimum_salary maximum_salary           experience  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience   \n",
       "1        ₹ 15.0L        ₹ 26.0L  2-4 yrs experience   \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience   \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience   \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience   \n",
       "5        ₹ 12.7L        ₹ 19.7L     1 yr experience   \n",
       "6         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience   \n",
       "7        ₹ 11.0L        ₹ 20.0L    4 yrs experience   \n",
       "8        ₹ 12.0L        ₹ 18.0L    4 yrs experience   \n",
       "9         ₹ 8.8L        ₹ 17.5L    3 yrs experience   "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe\n",
    "df=pd.DataFrame({'company':company, 'total_salary':total_salary, 'average_salary':average_salary, 'minimum_salary':minimum_salary, 'maximum_salary':maximum_salary, 'experience':experience })\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
